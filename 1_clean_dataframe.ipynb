{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Data Preparation\n",
    "\n",
    "Load Reddit Dataset: \n",
    "Import the Wallstreetbets dataset using pandas.\n",
    "Inspect the dataset structure (columns, missing values).\n",
    "\n",
    "Preprocess Reddit Posts:\n",
    "Clean the text data:\n",
    "Remove punctuation, special characters, and stopwords.\n",
    "Convert text to lowercase.\n",
    "\n",
    "Extract useful fields:\n",
    "Date: Convert timestamps to proper datetime format.\n",
    "Title/Text: Focus on titles or combine with post text.\n",
    "Filter data for relevant timeframes (e.g., GME short squeeze period).\n",
    "\n",
    "Stock Ticker Extractiond (GME):\n",
    "Use Named Entity Recognition (NER) to extract stock tickers and company mentions.\n",
    "Example tools: spaCy or regex patterns like GME.\n",
    "Save Cleaned Data:\n",
    "Save a cleaned dataset as a CSV for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import re\n",
    "import emoji\n",
    "import spacy\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_data = pd.read_csv('data/reddit_wsb.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You guys are champs. GME... who would have thought a bunch of crazy retards could reach the front page of the New York Times.\\n\\nAnd when you're done with GME, it's time to punish the big banks who have been suppressing the price of silver since the Bear Stearns / JPM merge. It's all in fucking Bloomberg:\\n\\n[https://www.bloomberg.com/news/articles/2019-09-16/precious-metals-traders-charged-with-rigging-futures-contracts](https://www.bloomberg.com/news/articles/2019-09-16/precious-metals-traders-charged-with-rigging-futures-contracts)\\n\\nThere's an excellent explanation of their scheme here\\n\\n[https://www.listennotes.com/podcasts/palisades-gold-radio/ted-butler-squeezing-out-the-hqxQ5mOdt02/](https://www.listennotes.com/podcasts/palisades-gold-radio/ted-butler-squeezing-out-the-hqxQ5mOdt02/)\\n\\nYou think GME squeezed hard? Look what happened to silver half a year ago in July:\\n\\n&#x200B;\\n\\nhttps://preview.redd.it/3yssvdm7y1e61.png?width=2588&format=png&auto=webp&s=25d4cfa973d57f1f6083affdcecf6b35e4055a7f\\n\\nThat's one of the banks getting squeezed out of silver, having to cover their shorts... and that's just because rich boomers freaked out about financial instability and finally started calling out the Comex on their bullshit, and taking physically delivery of silver... which they don't have.\\n\\nNow imagine 4 million degenerates buying $SLV, forcing the trust to take delivery of physical silver from the Comex. This isn't GME, who's fair price is maybe around $5 a share. The FAIR price of silver based on the historical gold/silver ratio is almost surely over $50/ounce. This short squeeze will be a fantastic success even if we can take silver to it's fair market value.\\n\\nAnd then there's $AG. Because once silver starts moving, $AG is going to go to the fucking moon. 1) it's a leverage play on silver, 2) It's got it's OWN SHORTS TO BE SQUEEZED OUT. At least a 23% short float as of last count: [https://shortsqueeze.com/shortinterest/stock/AG.htm](https://shortsqueeze.com/shortinterest/stock/AG.htm)\\n\\n**TL;DR: Once this thing gets going, shares and calls of $SLV and $AG will** ***rocket.***\\n\\nEdit: **ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€**\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_data.iloc[12]['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str):\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text) # remove hyperlinks\n",
    "    text = re.sub(r'[^\\w\\s$]', '', text)  # remove punctionation, keep '$' for tickers\n",
    "    text = re.sub(r'\\s+', ' ', text) # remove newlines and multiple spaces\n",
    "    text = emoji.demojize(text) # handle emojis. They may contain info for sentiment..?\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Na values: \n",
      "title            0\n",
      "score            0\n",
      "id               0\n",
      "url              0\n",
      "comms_num        0\n",
      "created          0\n",
      "body         28449\n",
      "timestamp        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check for na values. All of them in body\n",
    "print(f\"Na values: \\n{reddit_data.isna().sum()}\")\n",
    "reddit_data = reddit_data.dropna() \n",
    "\n",
    "# Only around half the data is left after this. I suspect, that titles without content wont be important for us. For now. I think we will continue with these.\n",
    "# It is worth considering, that there may be images in the body? But its far more likely, that the body was deleted ( I checked a few ).\n",
    "# Also, the number of comments may be interesting, as posts with many comments might contain more value for us.\n",
    "\n",
    "# Score - We dont know exactly what the scure means. It may be upvotes.\n",
    "# created - We drop this column, as we do have the timestamp column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_data['title'] = reddit_data['title'].map(clean_text)\n",
    "reddit_data['body'] = reddit_data['body'].map(clean_text)\n",
    "reddit_data = reddit_data.drop(columns=['url', 'created'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment the dataframe: We wish to capture all rows, that contain tickers and discuss specific stocks. \n",
    "# Especially GME and some of the others.\n",
    "\n",
    "# Tickers of interest (match with or without $)\n",
    "priority_tickers = ['TSLA', 'AMZN', 'AMC', 'SLV', 'AG', 'GME']\n",
    "\n",
    "# Regex to capture:\n",
    "# 1. Priority tickers (with or without $)\n",
    "# 2. Other tickers, but only if they have the $ sign\n",
    "ticker_pattern = r'\\b(?:\\$([A-Z]{2,5})|(?<!\\$)(' + '|'.join(priority_tickers) + r'))\\b'\n",
    "\n",
    "# Function to extract relevant tickers from text\n",
    "def extract_tickers(text):\n",
    "    matches = re.findall(ticker_pattern, text, re.IGNORECASE)\n",
    "    # Flatten the list and clean up empty matches\n",
    "    match_list = [match[0] if match[0] else match[1].upper() for match in matches]\n",
    "    match_text = ','.join(set(match_list))\n",
    "    return match_text\n",
    "\n",
    "# Apply extraction to the DataFrame\n",
    "reddit_data['extracted_tickers'] = reddit_data['body'].apply(extract_tickers)\n",
    "reddit_data['extracted_tickers'] = reddit_data['extracted_tickers'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag all rows with mentions of gme\n",
    "# First iterations, I only chose the posts that only discussed gme.\n",
    "reddit_data['gme'] = reddit_data['extracted_tickers'].str.contains('gme').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: this is the moment\n",
      "Body: life isnt fair my mother always told me that when i would complain about arbitrary treatment i would play by the rules and someone else would ignore them when they would win i would appeal to the first authority for an explanation are you going to let them get away with this life isnt fair no it is not the game is the game always in this moment the fascade cracks further when the first breach was made i do not know perhaps it was socrates but today i see thousands millions once they were laughing luxuries falling out of their disgusting diseased mouths as they cackled the unmistakable stench of derision carried on their breath they told anyone outside of their elite class that we were fools for even trying they told us that we were naive we needed networks to be successful we needed polish we needed expertise we needed them the game is the game always they are no longer laughing their odious oeuvre still wafts through the air while the rot and hate and condescention remains the noxious air betrays a new addition something all together disconcerting what it betrays is fear they are afraid and they should be we do not need their inherited resources masked as acumen a new day dawns the day where we make an ever so slight step towards what they fear the most an even field life becoming ever so slighty more fair and they are scared they look at us and see roughness we look at them and see softness we are both correct in our estimation the game is the game always fuck them in the street fuck them all in the street we are the righteous we are blessed by phoebe what started here will echo through time in the eons to come mount up and ride with the fury of a thousand rockets into the universal filament may the wind always be at your back and the sun upon your face and may the wings of destiny carry you aloft to dance with the stars gmeeverything bbeverything \n"
     ]
    }
   ],
   "source": [
    "# Inspect a single post and title\n",
    "title = reddit_data.iloc[2]['title']\n",
    "text = reddit_data.iloc[2]['body']\n",
    "print(f\"Title: {title}\")\n",
    "print(f\"Body: {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_data[reddit_data['gme'] == 1]\n",
    "reddit_data.to_csv('data/rd_clean.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>body</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>extracted_tickers</th>\n",
       "      <th>gme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>exit the system</td>\n",
       "      <td>0</td>\n",
       "      <td>l6uhhn</td>\n",
       "      <td>47</td>\n",
       "      <td>the ceo of nasdaq pushed to halt trading to gi...</td>\n",
       "      <td>2021-01-28 21:30:35</td>\n",
       "      <td>gme</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>short stock doesnt have an expiration date</td>\n",
       "      <td>317</td>\n",
       "      <td>l6uf6d</td>\n",
       "      <td>53</td>\n",
       "      <td>hedgefund whales are spreading disinfo saying ...</td>\n",
       "      <td>2021-01-28 21:26:27</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>this is the moment</td>\n",
       "      <td>405</td>\n",
       "      <td>l6ub9l</td>\n",
       "      <td>178</td>\n",
       "      <td>life isnt fair my mother always told me that w...</td>\n",
       "      <td>2021-01-28 21:19:31</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>we need to keep this movement going we all can...</td>\n",
       "      <td>222</td>\n",
       "      <td>l6uao1</td>\n",
       "      <td>70</td>\n",
       "      <td>i believe right now is one of those rare oppo...</td>\n",
       "      <td>2021-01-28 21:18:25</td>\n",
       "      <td>gme,amc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>once youre done with gme $ag and $slv the gent...</td>\n",
       "      <td>0</td>\n",
       "      <td>l6u9wu</td>\n",
       "      <td>16</td>\n",
       "      <td>you guys are champs gme who would have thought...</td>\n",
       "      <td>2021-01-28 21:17:10</td>\n",
       "      <td>gme</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53181</th>\n",
       "      <td>ten year price prediction for tsla</td>\n",
       "      <td>156</td>\n",
       "      <td>owfbxp</td>\n",
       "      <td>204</td>\n",
       "      <td>its all contingent on them mastering fsd but i...</td>\n",
       "      <td>2021-08-02 17:11:36</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53182</th>\n",
       "      <td>what i learned investigating sava fud spreaders</td>\n",
       "      <td>238</td>\n",
       "      <td>owd2pn</td>\n",
       "      <td>87</td>\n",
       "      <td>tldr three bitter scientists partnered up with...</td>\n",
       "      <td>2021-08-02 15:03:27</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53183</th>\n",
       "      <td>daily popular tickers thread for august 02 202...</td>\n",
       "      <td>228</td>\n",
       "      <td>owd1a5</td>\n",
       "      <td>1070</td>\n",
       "      <td>your daily hype thread please keep the shitpo...</td>\n",
       "      <td>2021-08-02 15:01:03</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53185</th>\n",
       "      <td>daily discussion thread for august 02 2021</td>\n",
       "      <td>338</td>\n",
       "      <td>owbfjf</td>\n",
       "      <td>11688</td>\n",
       "      <td>your daily trading discussion thread please ke...</td>\n",
       "      <td>2021-08-02 13:00:16</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53186</th>\n",
       "      <td>fraternal association of gambling gentlemen an...</td>\n",
       "      <td>40</td>\n",
       "      <td>owaqd6</td>\n",
       "      <td>810</td>\n",
       "      <td>this is an old yacht club thread click uvisual...</td>\n",
       "      <td>2021-08-02 12:00:14</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24738 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  score      id  \\\n",
       "2                                        exit the system      0  l6uhhn   \n",
       "6             short stock doesnt have an expiration date    317  l6uf6d   \n",
       "7                                     this is the moment    405  l6ub9l   \n",
       "10     we need to keep this movement going we all can...    222  l6uao1   \n",
       "12     once youre done with gme $ag and $slv the gent...      0  l6u9wu   \n",
       "...                                                  ...    ...     ...   \n",
       "53181                 ten year price prediction for tsla    156  owfbxp   \n",
       "53182    what i learned investigating sava fud spreaders    238  owd2pn   \n",
       "53183  daily popular tickers thread for august 02 202...    228  owd1a5   \n",
       "53185         daily discussion thread for august 02 2021    338  owbfjf   \n",
       "53186  fraternal association of gambling gentlemen an...     40  owaqd6   \n",
       "\n",
       "       comms_num                                               body  \\\n",
       "2             47  the ceo of nasdaq pushed to halt trading to gi...   \n",
       "6             53  hedgefund whales are spreading disinfo saying ...   \n",
       "7            178  life isnt fair my mother always told me that w...   \n",
       "10            70   i believe right now is one of those rare oppo...   \n",
       "12            16  you guys are champs gme who would have thought...   \n",
       "...          ...                                                ...   \n",
       "53181        204  its all contingent on them mastering fsd but i...   \n",
       "53182         87  tldr three bitter scientists partnered up with...   \n",
       "53183       1070   your daily hype thread please keep the shitpo...   \n",
       "53185      11688  your daily trading discussion thread please ke...   \n",
       "53186        810  this is an old yacht club thread click uvisual...   \n",
       "\n",
       "                 timestamp extracted_tickers  gme  \n",
       "2      2021-01-28 21:30:35               gme    1  \n",
       "6      2021-01-28 21:26:27                      0  \n",
       "7      2021-01-28 21:19:31                      0  \n",
       "10     2021-01-28 21:18:25           gme,amc    1  \n",
       "12     2021-01-28 21:17:10               gme    1  \n",
       "...                    ...               ...  ...  \n",
       "53181  2021-08-02 17:11:36                      0  \n",
       "53182  2021-08-02 15:03:27                      0  \n",
       "53183  2021-08-02 15:01:03                      0  \n",
       "53185  2021-08-02 13:00:16                      0  \n",
       "53186  2021-08-02 12:00:14                      0  \n",
       "\n",
       "[24738 rows x 8 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
